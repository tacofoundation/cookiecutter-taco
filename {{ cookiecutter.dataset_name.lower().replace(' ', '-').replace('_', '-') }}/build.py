"""
TACO Build Script - Infrastructure

This script orchestrates the complete TACO dataset build process.
It reads configuration from dataset/config.py and calls dataset/taco.py.

DO NOT EDIT THIS FILE - Modify files in the dataset/ directory instead.

Usage:
    python build.py
"""

import re
import shutil
from pathlib import Path

from tacotoolbox import create, create_tacocat, create_tacollection
from dataset.config import BUILD_CONFIG, PARQUET_CONFIG, TACOCAT_PARQUET_CONFIG
from dataset.taco import create_taco


def clean_previous_outputs(output: str):
    """
    Remove previous TACO outputs safely using regex patterns.

    Handles all possible output patterns:
    - Single file: output.tacozip, output.zip
    - Parts: output_part0001.tacozip, output_part0002.tacozip, ...
    - Group by: output_groupA.tacozip, output_groupB.tacozip, ...
    - FOLDER: output/
    - TacoCat: __TACOCAT__ (fixed name in parent directory)
    - TACOLLECTION: TACOLLECTION.json (in parent directory)
    - Docs: index.html, README.md (in parent directory)
    """
    output_path = Path(output)
    parent_dir = output_path.parent
    base_stem = output_path.stem

    # Remove suffix if present (.tacozip, .zip)
    if base_stem.endswith(".tacozip"):
        base_stem = base_stem[:-9]
    elif base_stem.endswith(".zip"):
        base_stem = base_stem[:-4]

    removed = []

    # Single files: output.tacozip, output.zip
    for ext in [".tacozip", ".zip"]:
        single_file = parent_dir / f"{base_stem}{ext}"
        if single_file.exists() and single_file.is_file():
            single_file.unlink()
            removed.append(str(single_file))

    # Parts: output_part0001.tacozip, output_part0002.tacozip, ...
    part_pattern = re.compile(rf"^{re.escape(base_stem)}_part\d{{4}}\.(tacozip|zip)$")
    for file in parent_dir.iterdir():
        if file.is_file() and part_pattern.match(file.name):
            file.unlink()
            removed.append(str(file))

    # Group by: output_*.tacozip, output_*.zip (but not _partXXXX)
    groupby_pattern = re.compile(
        rf"^{re.escape(base_stem)}_(?!part\d{{4}}).*\.(tacozip|zip)$"
    )
    for file in parent_dir.iterdir():
        if file.is_file() and groupby_pattern.match(file.name):
            file.unlink()
            removed.append(str(file))

    # FOLDER: output/
    folder_path = parent_dir / base_stem
    if folder_path.exists() and folder_path.is_dir():
        shutil.rmtree(folder_path)
        removed.append(str(folder_path))

    # TacoCat: __TACOCAT__ (fixed name)
    tacocat_path = parent_dir / "__TACOCAT__"
    if tacocat_path.exists() and tacocat_path.is_file():
        tacocat_path.unlink()
        removed.append(str(tacocat_path))

    # TACOLLECTION.json
    tacollection_path = parent_dir / "TACOLLECTION.json"
    if tacollection_path.exists() and tacollection_path.is_file():
        tacollection_path.unlink()
        removed.append(str(tacollection_path))

    # Documentation files
    for doc_file in ["index.html", "README.md"]:
        doc_path = parent_dir / doc_file
        if doc_path.exists() and doc_path.is_file():
            doc_path.unlink()
            removed.append(str(doc_path))

    if removed:
        print(f"Cleaned {len(removed)} previous output(s):")
        for item in removed:
            print(f"  - {item}")


def generate_documentation(output: str, config: dict):
    """Generate HTML and Markdown documentation."""
    from tacotoolbox import generate_html, generate_markdown
    
    output_path = Path(output)
    parent_dir = output_path.parent
    tacollection_path = parent_dir / "TACOLLECTION.json"
    
    print("\nGenerating documentation...")
    
    generate_html(
        input=tacollection_path,
        output=parent_dir / "index.html",
        download_base_url=config.get("download_base_url"),
        catalogue_url=config.get("catalogue_url", "https://tacofoundation.github.io/catalogue"),
    )
    
    generate_markdown(
        input=tacollection_path,
        output=parent_dir / "README.md",
    )
    
    print(f"Generated docs in {parent_dir}")


def main():
    """
    Build and write TACO dataset.
    
    Process:
    1. Clean previous outputs (if enabled in config)
    2. Build TACO by calling dataset.taco.create_taco()
    3. Write to disk in ZIP or FOLDER format
    4. If multiple ZIP parts created, generate TacoCat index and TACOLLECTION.json
    5. Generate HTML and Markdown documentation (if enabled)
    """
    output = BUILD_CONFIG["output"]
    format_type = BUILD_CONFIG["format"]
    clean_outputs = BUILD_CONFIG.get("clean_previous_outputs", True)
    validate_schema = BUILD_CONFIG.get("validate_schema", True)
    quiet = BUILD_CONFIG.get("quiet", False)

    # Step 1: Clean previous outputs
    if clean_outputs:
        print("Checking for previous outputs...")
        clean_previous_outputs(output)

    # Step 2: Build TACO object (calls user code in dataset/)
    taco = create_taco()

    # Step 3: Write to disk
    print(f"Writing TACO in {format_type.upper()} format to {output}...")

    if format_type == "zip":
        parts = create(taco, output, **PARQUET_CONFIG)

        # Step 4: If split into multiple parts, create TacoCat + TACOLLECTION
        if len(parts) > 1:
            print(f"Created {len(parts)} parts. Building TacoCat and TACOLLECTION...")
            output_path = Path(output)

            print(f"Creating __TACOCAT__ index in {output_path.parent}...")
            create_tacocat(
                inputs=parts,
                output=str(output_path.parent),
                parquet_kwargs=TACOCAT_PARQUET_CONFIG,
                validate_schema=validate_schema,
                quiet=quiet,
            )

            print(f"Creating TACOLLECTION.json in {output_path.parent}...")
            create_tacollection(
                inputs=parts,
                output=str(output_path.parent),
                validate_schema=validate_schema,
            )
        else:
            print("Single ZIP created. Generating TACOLLECTION.json...")
            output_path = Path(output)
            create_tacollection(
                inputs=parts,
                output=str(output_path.parent),
                validate_schema=validate_schema,
            )

    elif format_type == "folder":
        create(taco, output, backend="folder", **PARQUET_CONFIG)
        
        # Generate TACOLLECTION.json for FOLDER format too
        print("Generating TACOLLECTION.json...")
        output_path = Path(output)
        create_tacollection(
            inputs=[output_path],
            output=str(output_path.parent),
            validate_schema=validate_schema,
        )

    else:
        raise ValueError(f"Unknown format: {format_type}")

    # Step 5: Generate documentation
    if BUILD_CONFIG.get("generate_docs", True):
        generate_documentation(output, BUILD_CONFIG)

    print("Done!")


if __name__ == "__main__":
    main()